server:
  port: 8883

spring:
  application:
    name: search

  #数据源
  datasource:
    username: root
    password: 123456
    url: jdbc:mysql://10.21.32.168:3306/nameless_search?useSSL=false&characterEncoding=utf8&serverTimezone=Asia/Shanghai
    driver-class-name: com.mysql.cj.jdbc.Driver
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      initial-size: 10
      max-active: 60
      min-idle: 5
      #设置防火墙 监控
      filters: wall,mergeStat
      filter:
        #sql监控设置
        stat:
          #是否记录慢查询
          log-slow-sql: true
          #慢查询的sql时间  毫秒
          slow-sql-millis: 5000
      #监控信息页面 用户密码
      stat-view-servlet:
        login-username: diversion-system
        login-password: diversion-system-backend
        #默认开启
        enabled: true
        allow:
        deny:
      test-while-idle: true
      test-on-borrow: true

  data:
    redis:
      password: hthredis
      cluster:
        nodes: 10.21.32.86:6371,10.21.32.86:6372,10.21.32.39:6373,10.21.32.39:6374,10.21.32.147:6375,10.21.32.147:6376
        max-redirects: 3
      lettuce:
        pool:
          min-idle: 0
          max-idle: 8
          max-wait: -1ms
          max-active: 8
        cluster:
          refresh:
            adaptive: true
            period: 2000

  # 卡夫卡配置
  kafka:
    bootstrap-servers: 10.21.32.168:9092
    # 生产者
    producer:
      retries: 3 # 设置大于 0 的值，则客户端会将发送失败的记录重新发送
      batch-size: 16384
      buffer-memory: 33554432
      acks: 1
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 消费者
    consumer:
      group-id: default-group
      enable-auto-commit: false
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      max-poll-records: 500
    listener:
      # 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
      # RECORD
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交
      # BATCH
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交
      # TIME
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交
      # COUNT
      # TIME | COUNT　有一个条件满足时提交
      # COUNT_TIME
      # 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交
      # MANUAL
      # 手动调用Acknowledgment.acknowledge()后立即提交，一般使用这种
      # MANUAL_IMMEDIATE
      ack-mode: MANUAL_IMMEDIATE

dubbo:
  protocol:
    name: dubbo
    port: -1
    serialization: fastjson2
  registry:
    address: nacos://10.21.32.86:8848

mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl